from bs4 import BeautifulSoup
import requests

class Urlsetter(object):
    url = "http://www.fishpond.co.nz/Books/Fiction_Literature"
    r = requests.get(url)
    data = r.text
    soup = BeautifulSoup(r.content, "lxml")

class Webscraping(Urlsetter):

    def productName(self):
        product_name_results = []
        for productName in Urlsetter.soup.find_all("a", {"class": "blue_link fn url"}):
            product_name_results.append(productName.text)
        try:
            product_name_results[0]
        except IndexError:
            print("No products found found")
        return product_name_results


    def isbn(self):
        isbn_results = []
        for isbn in Urlsetter.soup.find_all("input", {"name": "barcode"}):
            isbn_results.append(isbn['value'])
        try:
            isbn_results[0]
        except IndexError:
            print("No ISBN found")
        return isbn_results


    def publishingDate(self):
        publishing_date_results = []
        for publishingDate in Urlsetter.soup.find_all("div",
                                         {"class": "productSearch-metainfo"}):
         publishing_date_results.append(publishingDate.text.split(',', 1)[-1])
        try:
            publishing_date_results[0]
        except IndexError:
            print("No publishing dates found")
        return publishing_date_results


    def RRP(self):
        rrp_results = []
        for rrp in Urlsetter.soup.find_all('s'):
            rrp_results.append(rrp.text[1:])
        try:
            rrp_results[0]
        except IndexError:
            print("No RRP found")
        return rrp_results


    def salePrices(self):
        sale_price_results = []
        for salePrice in Urlsetter.soup.find_all("span", {"class": "productSpecialPrice"}):
            sale_price_results.append(salePrice.text[1:])
        try:
            sale_price_results[0]
        except IndexError:
            print("No sale prices found")
        return sale_price_results


    def savingTotal(self):
        savings_results = []
        for savings in Urlsetter.soup.find_all("span", {"class": "you_save"}):
            savings_results.append(savings.text.partition('(')[-1].rpartition('%')[0])
        try:
            savings_results[0]
        except IndexError:
            print("No savings found")
        return savings_results


    def photoLink(self):
        photo_link_results = []
        for photoLink in Urlsetter.soup.find_all("img", {"class": "photo"}):
            photo_link_results.append(photoLink['src'])
        try:
            photo_link_results[0]
        except IndexError:
            print("No photo links found")
        return photo_link_results

